import numpy as np
import pandas as pd
from typing import Tuple, Dict, Optional
import torch
import torch.nn as nn
from transformers import PatchTSTConfig, PatchTSTForPrediction
from transformers import PatchTSTModel
from sklearn.metrics import mean_absolute_error, mean_squared_error
import joblib


class ForecastPatchTST:
    """PatchTST –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏ FORECAST"""
    
    def __init__(self, 
                 ModelConfig: Dict):
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è PatchTST
        self.config = PatchTSTConfig(**ModelConfig)
        
        self.model = None
        self.is_trained = False
        
        # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        torch.manual_seed(52)
        np.random.seed(52)
    
    def _create_model(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ PatchTST"""
        if self.model is None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º PatchTSTForPrediction –¥–ª—è forecasting –∑–∞–¥–∞—á
            self.model = PatchTSTForPrediction(self.config)
    
    def prepare_data_for_patchtst(self, X: np.ndarray, y: np.ndarray = None) -> Dict:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ PatchTST
        X: (batch_size, sequence_length, num_features)
        y: (batch_size, 2) - [return_1d, return_20d]
        """
        # PatchTST –æ–∂–∏–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ (batch_size, sequence_length, num_channels)
        # –ù–∞—à–∏ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ torch tensors
        past_values = torch.tensor(X, dtype=torch.float32)
        
        data_dict = {
            'past_values': past_values
        }
        
        if y is not None:
            # –î–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞–º –Ω—É–∂–Ω—ã future values
            # PatchTST –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –Ω–∞ prediction_length —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥
            # –ù–æ –Ω–∞–º –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã (1d, 20d)
            
            # –°–æ–∑–¥–∞–µ–º "—Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ" future_values –¥–ª—è compatibility
            batch_size = X.shape
            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–∞—Ä–≥–µ—Ç –¥–ª—è –≤—Å–µ—Ö prediction_length —à–∞–≥–æ–≤
            future_values = torch.zeros(batch_size, self.prediction_length, self.num_input_channels)
            
            data_dict['future_values'] = future_values
            data_dict['targets'] = torch.tensor(y, dtype=torch.float32)
        
        return data_dict
    
    def train(self, X_train: np.ndarray, y_train: np.ndarray,
              X_val: np.ndarray, y_val: np.ndarray,
              epochs: int = 50, batch_size: int = 32,
              learning_rate: float = 1e-4) -> Dict:
        """–û–±—É—á–µ–Ω–∏–µ PatchTST –º–æ–¥–µ–ª–∏"""
        
        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ PatchTST –º–æ–¥–µ–ª–∏")
        print(f"   –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
        print(f"   –†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_val.shape}")
        print(f"   Context length: {self.context_length}")
        print(f"   Prediction length: {self.prediction_length}")
        print(f"   Patch length: {self.patch_length}")
        
        self._create_model()
        
        train_data = self.prepare_data_for_patchtst(X_train, y_train)
        val_data = self.prepare_data_for_patchtst(X_val, y_val)
        
        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)
        
        # –î–ª—è tracking –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
        history = {
            'train_loss': [],
            'val_loss': [],
            'train_mae_1d': [],
            'val_mae_1d': [],
            'train_mae_20d': [],
            'val_mae_20d': []
        }
        
        best_val_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(epochs):
            # Training
            self.model.train()
            train_loss = 0.0
            train_mae_1d = 0.0
            train_mae_20d = 0.0
            
            # –ü—Ä–æ—Å—Ç–∞—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–º–æ–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å DataLoader)
            n_batches = (len(X_train) + batch_size - 1) // batch_size
            
            for batch_idx in range(n_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, len(X_train))
                
                batch_X = X_train[start_idx:end_idx]
                batch_y = y_train[start_idx:end_idx]
                
                batch_data = self.prepare_data_for_patchtst(batch_X, batch_y)
                
                optimizer.zero_grad()
                
                # Forward pass
                outputs = self.model(**{k: v for k, v in batch_data.items() if k != 'targets'})
                
                # –ö–∞—Å—Ç–æ–º–Ω–∞—è loss function –¥–ª—è –Ω–∞—à–∏—Ö —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤
                loss, mae_1d, mae_20d = self._calculate_custom_loss(outputs, batch_data['targets'])
                
                # Backward pass
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                train_mae_1d += mae_1d
                train_mae_20d += mae_20d
            
            # Validation
            self.model.eval()
            val_loss = 0.0
            val_mae_1d = 0.0
            val_mae_20d = 0.0
            
            with torch.no_grad():
                val_n_batches = (len(X_val) + batch_size - 1) // batch_size
                
                for batch_idx in range(val_n_batches):
                    start_idx = batch_idx * batch_size
                    end_idx = min(start_idx + batch_size, len(X_val))
                    
                    batch_X = X_val[start_idx:end_idx]
                    batch_y = y_val[start_idx:end_idx]
                    
                    batch_data = self.prepare_data_for_patchtst(batch_X, batch_y)
                    
                    outputs = self.model(**{k: v for k, v in batch_data.items() if k != 'targets'})
                    loss, mae_1d, mae_20d = self._calculate_custom_loss(outputs, batch_data['targets'])
                    
                    val_loss += loss.item()
                    val_mae_1d += mae_1d
                    val_mae_20d += mae_20d
            
            # –£—Å—Ä–µ–¥–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            train_loss /= n_batches
            train_mae_1d /= n_batches
            train_mae_20d /= n_batches
            val_loss /= val_n_batches
            val_mae_1d /= val_n_batches
            val_mae_20d /= val_n_batches
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            history['train_loss'].append(train_loss)
            history['val_loss'].append(val_loss)
            history['train_mae_1d'].append(train_mae_1d)
            history['val_mae_1d'].append(val_mae_1d)
            history['train_mae_20d'].append(train_mae_20d)
            history['val_mae_20d'].append(val_mae_20d)
            
            # Scheduler step
            scheduler.step(val_loss)
            
            # Early stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                torch.save(self.model.state_dict(), 'best_patchtst_model.pth')
            else:
                patience_counter += 1
            
            # Logging
            if epoch % 5 == 0:
                print(f"Epoch {epoch:3d}/{epochs}: "
                      f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, "
                      f"Val MAE 1d: {val_mae_1d:.4f}, Val MAE 20d: {val_mae_20d:.4f}")
            
            # Early stopping
            if patience_counter >= 10:
                print(f"Early stopping –Ω–∞ epoch {epoch}")
                break
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        self.model.load_state_dict(torch.load('best_patchtst_model.pth'))
        self.is_trained = True
        
        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        return history
    
    def _calculate_custom_loss(self, outputs, targets):
        """
        –ö–∞—Å—Ç–æ–º–Ω–∞—è loss —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—à–∏—Ö —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        outputs: —Ä–µ–∑—É–ª—å—Ç–∞—Ç PatchTST –º–æ–¥–µ–ª–∏
        targets: (batch_size, 2) - [return_1d, return_20d]
        """
        # PatchTST –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ prediction_length —à–∞–≥–æ–≤
        # –ù–∞–º –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π —à–∞–≥ (1d) –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥ (20d)
        predictions = outputs.prediction_outputs  # (batch_size, prediction_length, num_channels)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ü–µ–ª–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, close price)
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π (–∏–ª–∏ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å average –ø–æ –∫–∞–Ω–∞–ª–∞–º)
        pred_1d = predictions[:, 0, 0]   # –ü–µ—Ä–≤—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥, –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª
        pred_20d = predictions[:, -1, 0]  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥, –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª
        
        # –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        target_1d = targets[:, 0]
        target_20d = targets[:, 1]
        
        # MSE loss –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
        loss_1d = nn.functional.mse_loss(pred_1d, target_1d)
        loss_20d = nn.functional.mse_loss(pred_20d, target_20d)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è loss (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ—Å–∞)
        total_loss = loss_1d + loss_20d
        
        # MAE –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        mae_1d = nn.functional.l1_loss(pred_1d, target_1d).item()
        mae_20d = nn.functional.l1_loss(pred_20d, target_20d).item()
        
        return total_loss, mae_1d, mae_20d
    
    def predict(self, X: np.ndarray) -> Dict[str, np.ndarray]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è PatchTST –º–æ–¥–µ–ª–∏"""
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞! –í—ã–∑–æ–≤–∏—Ç–µ train() —Å–Ω–∞—á–∞–ª–∞.")
        
        self.model.eval()
        predictions = {'return_1d': [], 'return_20d': [], 'prob_1d': [], 'prob_20d': []}
        
        with torch.no_grad():
            # –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            batch_size = 32
            n_batches = (len(X) + batch_size - 1) // batch_size
            
            for batch_idx in range(n_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, len(X))
                
                batch_X = X[start_idx:end_idx]
                batch_data = self.prepare_data_for_patchtst(batch_X)
                
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                outputs = self.model(**batch_data)
                forecast = outputs.prediction_outputs  # (batch_size, prediction_length, num_channels)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω—É–∂–Ω—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã
                pred_1d = forecast[:, 0, 0].cpu().numpy()    # 1-day horizon
                pred_20d = forecast[:, -1, 0].cpu().numpy()  # 20-day horizon
                
                # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞ (sigmoid –æ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)
                prob_1d = torch.sigmoid(torch.tensor(pred_1d * 10)).cpu().numpy()  # Scaling factor
                prob_20d = torch.sigmoid(torch.tensor(pred_20d * 5)).cpu().numpy()
                
                # Clip –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
                prob_1d = np.clip(prob_1d, 0.1, 0.9)
                prob_20d = np.clip(prob_20d, 0.1, 0.9)
                
                predictions['return_1d'].extend(pred_1d)
                predictions['return_20d'].extend(pred_20d)
                predictions['prob_1d'].extend(prob_1d)
                predictions['prob_20d'].extend(prob_20d)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy arrays
        for key in predictions:
            predictions[key] = np.array(predictions[key])
        
        return predictions
    
    def evaluate_model(self, X_test: np.ndarray, 
                      y_test: np.ndarray) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ PatchTST –º–æ–¥–µ–ª–∏"""
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = self.predict(X_test)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = {}
        
        # MAE –¥–ª—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
        metrics['mae_1d'] = mean_absolute_error(y_test[:, 0], predictions['return_1d'])
        metrics['mae_20d'] = mean_absolute_error(y_test[:, 1], predictions['return_20d'])
        
        # RMSE –¥–ª—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
        metrics['rmse_1d'] = np.sqrt(mean_squared_error(y_test[:, 0], predictions['return_1d']))
        metrics['rmse_20d'] = np.sqrt(mean_squared_error(y_test[:, 1], predictions['return_20d']))
        
        # Direction Accuracy
        true_direction_1d = (y_test[:, 0] > 0).astype(int)
        pred_direction_1d = (predictions['return_1d'] > 0).astype(int)
        metrics['direction_accuracy_1d'] = np.mean(true_direction_1d == pred_direction_1d)
        
        true_direction_20d = (y_test[:, 1] > 0).astype(int)
        pred_direction_20d = (predictions['return_20d'] > 0).astype(int)
        metrics['direction_accuracy_20d'] = np.mean(true_direction_20d == pred_direction_20d)
        
        # Brier Score –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        true_prob_1d = (y_test[:, 0] > 0).astype(float)
        true_prob_20d = (y_test[:, 1] > 0).astype(float)
        
        metrics['brier_1d'] = np.mean((true_prob_1d - predictions['prob_1d']) ** 2)
        metrics['brier_20d'] = np.mean((true_prob_20d - predictions['prob_20d']) ** 2)
        
        return metrics
    
    def save_model(self, filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if self.model is not None:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'config': self.config,
                'context_length': self.context_length,
                'prediction_length': self.prediction_length,
                'num_input_channels': self.num_input_channels
            }, filepath)
            print(f"üíæ PatchTST –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filepath}")
    
    def load_model(self, filepath: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        checkpoint = torch.load(filepath)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config = checkpoint['config']
        self.context_length = checkpoint['context_length']
        self.prediction_length = checkpoint['prediction_length']
        self.num_input_channels = checkpoint['num_input_channels']
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        self._create_model()
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.is_trained = True
        
        print(f"üìÅ PatchTST –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {filepath}")


# –î–µ–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è PatchTST
def demo_patchtst():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã PatchTST –º–æ–¥–µ–ª–∏"""
    print("üß† –î–ï–ú–û: PatchTST –º–æ–¥–µ–ª—å")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ
    np.random.seed(42)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    n_samples = 500
    context_length = 96  # 96 –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏
    n_features = 12  # OHLCV + —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã + sentiment
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã —Å —Ç—Ä–µ–Ω–¥–æ–º
    X = []
    y = []
    
    for i in range(n_samples):
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å—é
        trend = np.linspace(100, 120, context_length)
        noise = np.random.randn(context_length, n_features) * 2
        base_series = trend.reshape(-1, 1) + noise
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ü–∏–∫–ª–∏—á–Ω–æ—Å—Ç—å
        time_idx = np.arange(context_length)
        seasonal = 5 * np.sin(2 * np.pi * time_idx / 20)
        base_series[:, 0] += seasonal  # –î–æ–±–∞–≤–ª—è–µ–º –∫ –ø–µ—Ä–≤–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É (close price)
        
        X.append(base_series)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å—é
        last_price = base_series[-1, 0]
        return_1d = np.random.randn() * 0.02 + np.tanh(base_series[-5:, 0].mean() - 110) * 0.01
        return_20d = return_1d * 1.5 + np.random.randn() * 0.03
        
        y.append([return_1d, return_20d])
    
    X = np.array(X)
    y = np.array(y)
    
    print(f"üìä –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"   X shape: {X.shape}")  
    print(f"   y shape: {y.shape}")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test
    train_size = int(0.7 * n_samples)
    val_size = int(0.15 * n_samples)
    
    X_train = X[:train_size]
    y_train = y[:train_size]
    X_val = X[train_size:train_size + val_size]
    y_val = y[train_size:train_size + val_size]
    X_test = X[train_size + val_size:]
    y_test = y[train_size + val_size:]
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º PatchTST –º–æ–¥–µ–ª—å
    model = ForecastPatchTST(
        context_length=context_length,
        prediction_length=20,  # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º –Ω–∞ 20 –¥–Ω–µ–π
        patch_length=12,  # –†–∞–∑–º–µ—Ä –ø–∞—Ç—á–∞
        num_input_channels=n_features,
        d_model=64,  # –ú–µ–Ω—å—à–µ –¥–ª—è –¥–µ–º–æ
        num_hidden_layers=2,
        num_attention_heads=4,
        dropout=0.1
    )
    
    # –û–±—É—á–µ–Ω–∏–µ (–º–µ–Ω—å—à–µ —ç–ø–æ—Ö –¥–ª—è –¥–µ–º–æ)
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    history = model.train(
        X_train, y_train,
        X_val, y_val,
        epochs=10,  # –ú–∞–ª–æ —ç–ø–æ—Ö –¥–ª—è –¥–µ–º–æ
        batch_size=16,
        learning_rate=1e-4
    )
    
    # –û—Ü–µ–Ω–∫–∞
    print(f"\nüìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ test –¥–∞–Ω–Ω—ã—Ö...")
    metrics = model.evaluate_model(X_test, y_test)
    
    print(f"\nüìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ PatchTST:")
    for metric_name, value in metrics.items():
        print(f"   {metric_name}: {value:.4f}")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–æ—Å—Ç–æ–π –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
    baseline_mae_1d = np.mean(np.abs(y_test[:, 0]))  # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º 0
    baseline_mae_20d = np.mean(np.abs(y_test[:, 1]))
    
    improvement_1d = (1 - metrics['mae_1d'] / baseline_mae_1d) * 100
    improvement_20d = (1 - metrics['mae_20d'] / baseline_mae_20d) * 100
    
    print(f"\nüéØ –£–ª—É—á—à–µ–Ω–∏–µ –Ω–∞–¥ baseline:")
    print(f"   1-day MAE: {improvement_1d:.1f}% –ª—É—á—à–µ")
    print(f"   20-day MAE: {improvement_20d:.1f}% –ª—É—á—à–µ")
    
    # –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    predictions = model.predict(X_test[:3])
    print(f"\nüîÆ –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
    for i in range(3):
        print(f"   –ü—Ä–∏–º–µ—Ä {i+1}:")
        print(f"     True 1d: {y_test[i, 0]:.4f}, Pred: {predictions['return_1d'][i]:.4f}")
        print(f"     True 20d: {y_test[i, 1]:.4f}, Pred: {predictions['return_20d'][i]:.4f}")
        print(f"     Prob up 1d: {predictions['prob_1d'][i]:.3f}")
        print(f"     Prob up 20d: {predictions['prob_20d'][i]:.3f}")


# Unit-—Ç–µ—Å—Ç
def test_patchtst():
    """Unit-—Ç–µ—Å—Ç –¥–ª—è PatchTST –º–æ–¥–µ–ª–∏"""
    print("üß™ Unit-—Ç–µ—Å—Ç –¥–ª—è PatchTST...")
    
    # –°–æ–∑–¥–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    X_test = np.random.randn(10, 24, 5)  # 10 –ø—Ä–∏–º–µ—Ä–æ–≤, 24 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–∞, 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    y_test = np.random.randn(10, 2)      # 2 —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = ForecastPatchTST(
        context_length=24, 
        prediction_length=5,
        num_input_channels=5, 
        patch_length=6,
        d_model=32,
        num_hidden_layers=1
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model._create_model()
    assert model.model is not None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö
    data_dict = model.prepare_data_for_patchtst(X_test, y_test)
    assert 'past_values' in data_dict
    assert data_dict['past_values'].shape == (10, 24, 5)
    
    print("‚úÖ Unit-—Ç–µ—Å—Ç PatchTST –ø—Ä–æ–π–¥–µ–Ω!")
